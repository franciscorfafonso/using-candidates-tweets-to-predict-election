{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Media Analytics\n",
    "# Twitter data collection\n",
    "## Full archive search\n",
    "### Requires Twitter research account\n",
    "\n",
    "(c) Nuno Ant√≥nio 2021-2022 - Version 1.03 (for API 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and do the initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter account settings\n",
    "# Verify details on https://developer.twitter.com/en/portal/dashboard\n",
    "\n",
    "bearer_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of user details\n",
    "def searchAuthorID(aID,usersObj):\n",
    "    index = -1\n",
    "    for user in usersObj:\n",
    "        index = index + 1\n",
    "        if user.id==aID:\n",
    "            break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of place\n",
    "def searchPlacesID(pID,placesObj):\n",
    "    index = -1\n",
    "    for place in placesObj:\n",
    "        index = index + 1\n",
    "        if place.id==pID:\n",
    "            break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection functions - from Twitter sample code: https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/master/Full-Archive-Search/full-archive-search.py\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    errCounter=0\n",
    "    while errCounter<10:\n",
    "        try:\n",
    "            response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "            print(response.status_code)\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(response.status_code, response.text)\n",
    "            break\n",
    "        except:\n",
    "            errCounter = errCounter+1\n",
    "            time.sleep(1)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the next page\n",
    "def query_page(url, header, query_params):\n",
    "\n",
    "    # Connects to endpoint and collects the data\n",
    "    json_response = connect_to_endpoint(url, header, query_params)\n",
    "\n",
    "    # Dumps the json object into an element\n",
    "    json_str = json.dumps(json_response)\n",
    "\n",
    "    # Loads the json to an object\n",
    "    resp = json.loads(json_str, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))\n",
    "\n",
    "    # Returns\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search definitions\n",
    "For details on how to build seach queries and filters check:\n",
    "- https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "- https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all\n",
    "- https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "- https://developer.twitter.com/en/support/twitter-api/error-troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates\n",
    "#search_text = '(from:Booker4KY OR from:JohnKennedyLA OR from:GaryChambersJr OR from:LukeMixonLA OR from:SupportSyrita OR from:VanHollenForMD OR from:ChaffeeUSSenate OR from:Schmitt4Senate OR from:buschvalentine OR from:JonathanDine OR from:CortezMasto OR from:AdamLaxalt OR from:Maggie_Hassan OR from:GenDonBolduc OR from:jeremykauffman OR from:chuckschumer OR from:JosephPinion OR from:TedBuddNC OR from:CheriBeasleyNC OR from:ShannonBrayNC OR from:hoeven4senate OR from:katrina_senate OR from:JDVance1 OR from:TimRyan OR from:jameslankford OR from:madisonhornok OR from:mchdlny OR from:LibertyCowboyKB OR from:MarkwayneMullin OR from:VoteKendraOK OR from:WydenForOregon OR from:PerkinsPerspect OR from:JohnFetterman OR from:DrOz OR from:Erik4Senate OR from:votetimscott OR from:johnthune OR from:BrianBengs OR from:Lesnar4USSENATE OR from:MikeLeeforUtah OR from:EvanMcMullin OR from:JamesArtHansen OR from:WelchForVT OR from:MurrayCampaign OR from:SmileyForWA OR from:RonJohnsonWI OR from:TheOtherMandela) is:retweet'\n",
    "search_text = '(from:KatieBrittforAL OR from:willboydforAL OR from:LisaForSenate OR from:KellyForAlaska OR from:CaptMarkKelly OR from:bgmasters OR from:Victor4Senate OR from:Boozman4AR OR from:JamesForAR OR from:SenAlexPadilla OR from:MarkMeuser OR from:MichaelBennet OR from:ODeaForColorado OR from:DickBlumenthal OR from:LeoraLevyCT OR from:TeamMarco OR from:valdemings OR from:ReverendWarnock OR from:HerschelWalker OR from:SchatzforHawaii OR from:repbobmcdermott OR from:crapoforsenate OR from:rothforIdaho OR from:TammyDuckworth OR from:salviforsenate OR from:BillRedpath OR from:ToddYoungIN OR from:gomcdermott OR from:sceniak4senate OR from:GrassleyWorks OR from:FrankenforIowa OR from:moranforkansas OR from:Holland4Kansas OR from:RandPaul) has:media'\n",
    "\n",
    "beginDate = '2022-03-01T00:00:00.000Z'\n",
    "endDate = '2022-11-07T23:59:59.999Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full query\n",
    "full_query = {'query': search_text,\n",
    "              'end_time': endDate,\n",
    "              'start_time':beginDate,\n",
    "              'max_results':500,\n",
    "              'tweet.fields': 'author_id,created_at,public_metrics,text,geo',\n",
    "              'expansions':'author_id,geo.place_id',\n",
    "              'user.fields':'created_at,username,public_metrics,url,verified',\n",
    "              'place.fields':'country,country_code,id,name,place_type'\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create headers for authentication\n",
    "headers = create_headers(bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop initializations\n",
    "\n",
    "# Next_token\n",
    "next_token=''\n",
    "\n",
    "# Create an empty list for tweets\n",
    "tws = []\n",
    "\n",
    "# Counters\n",
    "pageCounter = 1\n",
    "collected = 0\n",
    "\n",
    "# Variables to control time between requests because of limits\n",
    "requestsPer15Min = 300\n",
    "requestsPerSec = 1\n",
    "secsBetweenRequests = int(15*60/requestsPer15Min)+1\n",
    "\n",
    "# Last request time\n",
    "lastRequest = datetime.now() + timedelta(seconds=-secsBetweenRequests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:40:14 waiting 4.0 seconds\n",
      "Page: 1 - start: 10:40:18\n",
      "200\n",
      "Page: 1 - end: 10:40:21 \n",
      " Last tweet date: 2022-11-04T03:02:07.000Z Collected: 498\n",
      "10:40:21 waiting 4.0 seconds\n",
      "Page: 2 - start: 10:40:25\n",
      "200\n",
      "Page: 2 - end: 10:40:27 \n",
      " Last tweet date: 2022-10-30T13:02:01.000Z Collected: 995\n",
      "10:40:27 waiting 4.0 seconds\n",
      "Page: 3 - start: 10:40:31\n",
      "200\n",
      "Page: 3 - end: 10:40:33 \n",
      " Last tweet date: 2022-10-24T23:14:47.000Z Collected: 1492\n",
      "10:40:33 waiting 4.0 seconds\n",
      "Page: 4 - start: 10:40:37\n",
      "200\n",
      "Page: 4 - end: 10:40:40 \n",
      " Last tweet date: 2022-10-18T11:52:34.000Z Collected: 1991\n",
      "10:40:40 waiting 4.0 seconds\n",
      "Page: 5 - start: 10:40:44\n",
      "200\n",
      "Page: 5 - end: 10:40:46 \n",
      " Last tweet date: 2022-10-10T23:44:54.000Z Collected: 2489\n",
      "10:40:46 waiting 4.0 seconds\n",
      "Page: 6 - start: 10:40:50\n",
      "200\n",
      "Page: 6 - end: 10:40:52 \n",
      " Last tweet date: 2022-09-29T11:21:23.000Z Collected: 2986\n",
      "10:40:52 waiting 4.0 seconds\n",
      "Page: 7 - start: 10:40:56\n",
      "200\n",
      "Page: 7 - end: 10:40:58 \n",
      " Last tweet date: 2022-09-17T23:16:14.000Z Collected: 3485\n",
      "10:40:58 waiting 4.0 seconds\n",
      "Page: 8 - start: 10:41:02\n",
      "200\n",
      "Page: 8 - end: 10:41:05 \n",
      " Last tweet date: 2022-09-07T15:18:35.000Z Collected: 3983\n",
      "10:41:05 waiting 4.0 seconds\n",
      "Page: 9 - start: 10:41:09\n",
      "200\n",
      "Page: 9 - end: 10:41:11 \n",
      " Last tweet date: 2022-08-26T00:37:54.000Z Collected: 4476\n",
      "10:41:11 waiting 4.0 seconds\n",
      "Page: 10 - start: 10:41:15\n",
      "200\n",
      "Page: 10 - end: 10:41:17 \n",
      " Last tweet date: 2022-08-14T21:44:45.000Z Collected: 4974\n",
      "10:41:17 waiting 4.0 seconds\n",
      "Page: 11 - start: 10:41:21\n",
      "200\n",
      "Page: 11 - end: 10:41:24 \n",
      " Last tweet date: 2022-08-03T03:09:00.000Z Collected: 5473\n",
      "10:41:24 waiting 4.0 seconds\n",
      "Page: 12 - start: 10:41:28\n",
      "200\n",
      "Page: 12 - end: 10:41:30 \n",
      " Last tweet date: 2022-07-19T16:26:18.000Z Collected: 5972\n",
      "10:41:30 waiting 4.0 seconds\n",
      "Page: 13 - start: 10:41:34\n",
      "200\n",
      "Page: 13 - end: 10:41:36 \n",
      " Last tweet date: 2022-07-02T18:47:55.000Z Collected: 6470\n",
      "10:41:36 waiting 4.0 seconds\n",
      "Page: 14 - start: 10:41:40\n",
      "200\n",
      "Page: 14 - end: 10:41:42 \n",
      " Last tweet date: 2022-06-18T14:05:09.000Z Collected: 6970\n",
      "10:41:42 waiting 4.0 seconds\n",
      "Page: 15 - start: 10:41:46\n",
      "200\n",
      "Page: 15 - end: 10:41:49 \n",
      " Last tweet date: 2022-06-03T20:24:32.000Z Collected: 7469\n",
      "10:41:49 waiting 4.0 seconds\n",
      "Page: 16 - start: 10:41:53\n",
      "200\n",
      "Page: 16 - end: 10:41:54 \n",
      " Last tweet date: 2022-05-17T17:12:37.000Z Collected: 7968\n",
      "10:41:54 waiting 4.0 seconds\n",
      "Page: 17 - start: 10:41:58\n",
      "200\n",
      "Page: 17 - end: 10:42:00 \n",
      " Last tweet date: 2022-05-03T12:49:19.000Z Collected: 8466\n",
      "10:42:00 waiting 4.0 seconds\n",
      "Page: 18 - start: 10:42:04\n",
      "200\n",
      "Page: 18 - end: 10:42:07 \n",
      " Last tweet date: 2022-04-15T21:20:06.000Z Collected: 8964\n",
      "10:42:07 waiting 4.0 seconds\n",
      "Page: 19 - start: 10:42:11\n",
      "200\n",
      "Page: 19 - end: 10:42:12 \n",
      " Last tweet date: 2022-03-28T18:05:56.000Z Collected: 9462\n",
      "10:42:12 waiting 4.0 seconds\n",
      "Page: 20 - start: 10:42:16\n",
      "200\n",
      "Page: 20 - end: 10:42:18 \n",
      " Last tweet date: 2022-03-07T20:24:10.000Z Collected: 9959\n",
      "10:42:18 waiting 4.0 seconds\n",
      "Page: 21 - start: 10:42:22\n",
      "200\n",
      "Page: 21 - end: 10:42:23 \n",
      " Last tweet date: 2022-03-01T03:37:11.000Z Collected: 10122\n"
     ]
    }
   ],
   "source": [
    "# Loop until there are no more \"next_token\"\n",
    "while True:\n",
    "\n",
    "    # Wait the time between requests to avoid being over limits\n",
    "    now = datetime.now()\n",
    "    secsSinceLastRequest = (lastRequest-lastRequest).total_seconds()\n",
    "    if secsSinceLastRequest<secsBetweenRequests:\n",
    "        secsToWait = secsBetweenRequests-secsSinceLastRequest\n",
    "        print(now.strftime(\"%H:%M:%S\"),f\"waiting {secsToWait} seconds\")\n",
    "        time.sleep(secsToWait)\n",
    "\n",
    "    # Give feedback\n",
    "    lastRequest = datetime.now()\n",
    "    current_time = lastRequest.strftime(\"%H:%M:%S\")\n",
    "    print(\"Page:\", pageCounter,'- start:',current_time)\n",
    "\n",
    "    # Build query and get results for page\n",
    "    query_params = full_query\n",
    "    if next_token!='':\n",
    "        query_params[\"next_token\"] = next_token\n",
    "    json_response = connect_to_endpoint(search_url, headers, query_params)\n",
    "    \n",
    "    # Transform json to object\n",
    "    json_str = json.dumps(json_response)\n",
    "    resp = json.loads(json_str, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))\n",
    "\n",
    "    # If there are tweets in the response\n",
    "    if resp.meta.result_count>0:\n",
    "\n",
    "        # Add results to list\n",
    "        for tweet in resp.data:\n",
    "            userIndex = searchAuthorID(tweet.author_id,resp.includes.users)\n",
    "            try:\n",
    "                placeIndex = searchPlacesID(tweet.geo.place_id, resp.includes.places)\n",
    "            except:\n",
    "                placeIndex = -1\n",
    "            tw=[tweet.id,\n",
    "                tweet.text,\n",
    "                tweet.author_id,\n",
    "                tweet.created_at,\n",
    "                tweet.public_metrics.retweet_count,\n",
    "                tweet.public_metrics.reply_count,\n",
    "                tweet.public_metrics.like_count,\n",
    "                tweet.public_metrics.quote_count,\n",
    "                resp.includes.users[userIndex].id,\n",
    "                resp.includes.users[userIndex].username,\n",
    "                resp.includes.users[userIndex].created_at,\n",
    "                resp.includes.users[userIndex].public_metrics.followers_count,\n",
    "                resp.includes.users[userIndex].public_metrics.following_count,\n",
    "                resp.includes.users[userIndex].public_metrics.tweet_count,\n",
    "                resp.includes.users[userIndex].public_metrics.listed_count,\n",
    "                resp.includes.users[userIndex].verified,\n",
    "                resp.includes.places[placeIndex].country_code if placeIndex!=-1 else '',\n",
    "                resp.includes.places[placeIndex].country if placeIndex!=-1 else '',\n",
    "                resp.includes.places[placeIndex].full_name if placeIndex!=-1 else '',\n",
    "                resp.includes.places[placeIndex].place_type if placeIndex!=-1 else ''\n",
    "            ]\n",
    "            tws.append(tw)\n",
    "            collected = collected + 1\n",
    "\n",
    "        # Give feedback of the page processing\n",
    "        ended = datetime.now()\n",
    "        current_time = ended.strftime(\"%H:%M:%S\")\n",
    "        print(\"Page:\", pageCounter,'- end:',current_time,'\\n','Last tweet date:',tweet.created_at, 'Collected:',collected)\n",
    "\n",
    "    # Test if there is a next_token to continue retrieval or if it should stop\n",
    "    try:\n",
    "        next_token = resp.meta.next_token\n",
    "        pageCounter = pageCounter + 1\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "tweetsDF = pd.DataFrame(tws, columns=['id',\n",
    "            'text',\n",
    "            'author_id',\n",
    "            'created_at',\n",
    "            'public_metrics.retweet_count',\n",
    "            'public_metrics.reply_count',\n",
    "            'public_metrics.like_count',\n",
    "            'public_metrics.quote_count',\n",
    "            'user.id',\n",
    "            'user.username',\n",
    "            'user.created_at',\n",
    "            'user.public_metrics.followers_count',\n",
    "            'user.public_metrics.following_count',\n",
    "            'user.public_metrics.tweet_count',\n",
    "            'user.public_metrics.listed_count',\n",
    "            'user.verified',\n",
    "            'place.country_code',\n",
    "            'place.country',\n",
    "            'place.full_name',\n",
    "            'place.place_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweetsDF.to_csv(\"Tweets.csv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "d7a18bc08bf6b314cad8b0dd8f53415ad78d1015cc806d14e4873c235fb4e191"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
