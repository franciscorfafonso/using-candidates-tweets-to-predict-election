{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/franciscorfafonso/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Loading packages\n",
    "\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57790 entries, 0 to 58446\n",
      "Data columns (total 20 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      57790 non-null  object \n",
      " 1   text                          57790 non-null  object \n",
      " 2   created_at                    57790 non-null  object \n",
      " 3   campaign_week                 57790 non-null  int64  \n",
      " 4   process_text_check            57790 non-null  object \n",
      " 5   name                          57790 non-null  object \n",
      " 6   handle                        57790 non-null  object \n",
      " 7   party                         57790 non-null  object \n",
      " 8   state_code                    57790 non-null  object \n",
      " 9   state_name                    57790 non-null  object \n",
      " 10  result_pctg                   57790 non-null  float64\n",
      " 11  result_votes                  57790 non-null  int64  \n",
      " 12  position                      57790 non-null  int64  \n",
      " 13  total_votes_casted            57790 non-null  int64  \n",
      " 14  winner_margin_for_runners_up  57790 non-null  float64\n",
      " 15  check_city_filtered           20226 non-null  object \n",
      " 16  PreProcessedText_WithoutCity  57790 non-null  object \n",
      " 17  Words                         57790 non-null  object \n",
      " 18  WordsCleaned                  57790 non-null  object \n",
      " 19  WordsLemmatized               57790 non-null  object \n",
      "dtypes: float64(2), int64(4), object(14)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from the pickle file\n",
    "df = pd.read_pickle('data_preprocessed_filtered.pkl')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create dictionary (needed for LDA)\n",
    "id2word = corpora.Dictionary(df['WordsLemmatized'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Create corpus\n",
    "texts = df['WordsLemmatized']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create TDM (Frequency)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# supporting function\n",
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k):\n",
    "\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k,\n",
    "                                           random_state=100,\n",
    "                                           chunksize=1000,\n",
    "                                           passes=50)\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "\n",
    "    return coherence_model_lda.get_coherence()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Hypertune***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [02:36<36:29, 156.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 5 topics: 0.48910919287842136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [05:14<34:06, 157.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 6 topics: 0.48727876395053094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [07:47<31:07, 155.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 7 topics: 0.4907975867619279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [10:22<28:27, 155.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 8 topics: 0.4662316786202284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [13:05<26:20, 158.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 9 topics: 0.5201712965889764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [15:38<23:25, 156.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 10 topics: 0.5187084053150935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [18:21<21:06, 158.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 11 topics: 0.5214625870331038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [20:45<17:57, 153.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 12 topics: 0.5195117637937859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [23:11<15:08, 151.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 13 topics: 0.5411883052044304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [25:42<12:36, 151.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 14 topics: 0.493154486713588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [28:23<10:17, 154.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 15 topics: 0.4958139090313243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [30:46<07:32, 150.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 16 topics: 0.5248908443948886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [33:11<04:57, 148.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 17 topics: 0.5073611053634252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [35:40<02:29, 149.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 18 topics: 0.5093934270809797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [38:08<00:00, 152.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence for 19 topics: 0.5206665548658689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 5\n",
    "max_topics = 20\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [corpus]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Coherence': []\n",
    "                 }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(topics_range)*len(corpus_title)))\n",
    "\n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # get the coherence score for the given parameters\n",
    "            cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, k=k)\n",
    "            print(f\"Coherence for {k} topics: {cv}\")  # Print coherence score for each topic\n",
    "            # Save the model results\n",
    "            model_results['Validation_Set'].append(corpus_title[i])\n",
    "            model_results['Topics'].append(k)\n",
    "            model_results['Coherence'].append(cv)\n",
    "\n",
    "            pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [2:36:11<00:00, 156.20s/it]  \n"
     ]
    }
   ],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k,a,b):\n",
    "\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k,\n",
    "                                           random_state=100,\n",
    "                                           chunksize=1000,\n",
    "                                           passes=50,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "#grid search with the number of topics with the best baseline coherence value\n",
    "topics_range = [13,9]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [corpus]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                 }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "\n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word,\n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "\n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.022*\"thank\" + 0.017*\"support\" + 0.016*\"u\" + 0.015*\"day\" + 0.015*\"state\" + 0.013*\"work\" + 0.012*\"senate\" + 0.011*\"people\" + 0.010*\"fight\" + 0.010*\"senator\"'), (1, '0.014*\"today\" + 0.014*\"one\" + 0.011*\"year\" + 0.011*\"name\" + 0.010*\"please\" + 0.009*\"help\" + 0.009*\"going\" + 0.009*\"lee\" + 0.008*\"paul\" + 0.007*\"mike\"'), (2, '0.021*\"people\" + 0.014*\"like\" + 0.012*\"would\" + 0.012*\"know\" + 0.011*\"say\" + 0.011*\"want\" + 0.010*\"think\" + 0.008*\"party\" + 0.008*\"one\" + 0.007*\"said\"'), (3, '0.065*\"right\" + 0.036*\"woman\" + 0.023*\"abortion\" + 0.017*\"freedom\" + 0.015*\"protect\" + 0.013*\"choice\" + 0.012*\"life\" + 0.011*\"decision\" + 0.011*\"court\" + 0.011*\"ban\"'), (4, '0.051*\"biden\" + 0.033*\"border\" + 0.024*\"joe\" + 0.020*\"policy\" + 0.016*\"crime\" + 0.015*\"crisis\" + 0.013*\"agenda\" + 0.012*\"ron\" + 0.012*\"democrat\" + 0.010*\"country\"'), (5, '0.024*\"energy\" + 0.022*\"american\" + 0.020*\"war\" + 0.019*\"oil\" + 0.018*\"big\" + 0.015*\"trump\" + 0.015*\"america\" + 0.015*\"president\" + 0.012*\"ukraine\" + 0.012*\"amp\"'), (6, '0.087*\"vote\" + 0.034*\"get\" + 0.033*\"election\" + 0.030*\"day\" + 0.030*\"make\" + 0.020*\"voting\" + 0.019*\"ballot\" + 0.017*\"voter\" + 0.015*\"th\" + 0.015*\"sure\"'), (7, '0.045*\"help\" + 0.043*\"u\" + 0.032*\"senate\" + 0.025*\"$\" + 0.019*\"campaign\" + 0.018*\"win\" + 0.018*\"*\" + 0.017*\"need\" + 0.016*\"chip\" + 0.015*\"race\"'), (8, '0.034*\"veteran\" + 0.032*\"gun\" + 0.029*\"act\" + 0.026*\"bill\" + 0.020*\"violence\" + 0.018*\"voted\" + 0.016*\"legislation\" + 0.015*\"water\" + 0.015*\"care\" + 0.014*\"common\"'), (9, '0.042*\"great\" + 0.029*\"county\" + 0.018*\"morning\" + 0.017*\"see\" + 0.016*\"join\" + 0.014*\"tonight\" + 0.014*\"thanks\" + 0.013*\"night\" + 0.013*\"today\" + 0.012*\"event\"'), (10, '0.044*\"$\" + 0.032*\"tax\" + 0.025*\"%\" + 0.022*\"business\" + 0.016*\"year\" + 0.016*\"spending\" + 0.016*\"inflation\" + 0.015*\"small\" + 0.013*\"pay\" + 0.013*\"american\"'), (11, '0.025*\"community\" + 0.025*\"child\" + 0.021*\"school\" + 0.018*\"law\" + 0.018*\"public\" + 0.017*\"need\" + 0.016*\"amp\" + 0.012*\"enforcement\" + 0.012*\"state\" + 0.011*\"support\"'), (12, '0.025*\"cost\" + 0.022*\"working\" + 0.022*\"family\" + 0.021*\"price\" + 0.017*\"american\" + 0.016*\"job\" + 0.015*\"inflation\" + 0.012*\"lower\" + 0.011*\"care\" + 0.010*\"get\"')]\n"
     ]
    }
   ],
   "source": [
    "#given the results of the grid search, the best model has 13 topics, alpha=asymmetric and beta=0.31\n",
    "# Build LDA model\n",
    "num_topics = 13\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       random_state=100,\n",
    "                                       chunksize=1000,\n",
    "                                       passes=50,\n",
    "                                       alpha='asymmetric',\n",
    "                                       eta=0.01)\n",
    "\n",
    "print(lda_model.print_topics())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5625463111357373\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.022*\"thank\" + 0.017*\"support\" + 0.016*\"u\" + 0.015*\"day\" + 0.015*\"state\" + 0.013*\"work\" + 0.012*\"senate\" + 0.011*\"people\" + 0.010*\"fight\" + 0.010*\"senator\"'), (1, '0.014*\"today\" + 0.014*\"one\" + 0.011*\"year\" + 0.011*\"name\" + 0.010*\"please\" + 0.009*\"help\" + 0.009*\"going\" + 0.009*\"lee\" + 0.008*\"paul\" + 0.007*\"mike\"'), (2, '0.021*\"people\" + 0.014*\"like\" + 0.012*\"would\" + 0.012*\"know\" + 0.011*\"say\" + 0.011*\"want\" + 0.010*\"think\" + 0.008*\"party\" + 0.008*\"one\" + 0.007*\"said\"'), (3, '0.065*\"right\" + 0.036*\"woman\" + 0.023*\"abortion\" + 0.017*\"freedom\" + 0.015*\"protect\" + 0.013*\"choice\" + 0.012*\"life\" + 0.011*\"decision\" + 0.011*\"court\" + 0.011*\"ban\"'), (4, '0.051*\"biden\" + 0.033*\"border\" + 0.024*\"joe\" + 0.020*\"policy\" + 0.016*\"crime\" + 0.015*\"crisis\" + 0.013*\"agenda\" + 0.012*\"ron\" + 0.012*\"democrat\" + 0.010*\"country\"'), (5, '0.024*\"energy\" + 0.022*\"american\" + 0.020*\"war\" + 0.019*\"oil\" + 0.018*\"big\" + 0.015*\"trump\" + 0.015*\"america\" + 0.015*\"president\" + 0.012*\"ukraine\" + 0.012*\"amp\"'), (6, '0.087*\"vote\" + 0.034*\"get\" + 0.033*\"election\" + 0.030*\"day\" + 0.030*\"make\" + 0.020*\"voting\" + 0.019*\"ballot\" + 0.017*\"voter\" + 0.015*\"th\" + 0.015*\"sure\"'), (7, '0.045*\"help\" + 0.043*\"u\" + 0.032*\"senate\" + 0.025*\"$\" + 0.019*\"campaign\" + 0.018*\"win\" + 0.018*\"*\" + 0.017*\"need\" + 0.016*\"chip\" + 0.015*\"race\"'), (8, '0.034*\"veteran\" + 0.032*\"gun\" + 0.029*\"act\" + 0.026*\"bill\" + 0.020*\"violence\" + 0.018*\"voted\" + 0.016*\"legislation\" + 0.015*\"water\" + 0.015*\"care\" + 0.014*\"common\"'), (9, '0.042*\"great\" + 0.029*\"county\" + 0.018*\"morning\" + 0.017*\"see\" + 0.016*\"join\" + 0.014*\"tonight\" + 0.014*\"thanks\" + 0.013*\"night\" + 0.013*\"today\" + 0.012*\"event\"'), (10, '0.044*\"$\" + 0.032*\"tax\" + 0.025*\"%\" + 0.022*\"business\" + 0.016*\"year\" + 0.016*\"spending\" + 0.016*\"inflation\" + 0.015*\"small\" + 0.013*\"pay\" + 0.013*\"american\"'), (11, '0.025*\"community\" + 0.025*\"child\" + 0.021*\"school\" + 0.018*\"law\" + 0.018*\"public\" + 0.017*\"need\" + 0.016*\"amp\" + 0.012*\"enforcement\" + 0.012*\"state\" + 0.011*\"support\"'), (12, '0.025*\"cost\" + 0.022*\"working\" + 0.022*\"family\" + 0.021*\"price\" + 0.017*\"american\" + 0.016*\"job\" + 0.015*\"inflation\" + 0.012*\"lower\" + 0.011*\"care\" + 0.010*\"get\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
